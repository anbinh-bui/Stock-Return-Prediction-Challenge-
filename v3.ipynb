{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>INDUSTRY</th>\n",
       "      <th>INDUSTRY_GROUP</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>RET_1</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>...</th>\n",
       "      <th>VOLUME_16</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_17</th>\n",
       "      <th>RET_18</th>\n",
       "      <th>VOLUME_18</th>\n",
       "      <th>RET_19</th>\n",
       "      <th>VOLUME_19</th>\n",
       "      <th>RET_20</th>\n",
       "      <th>VOLUME_20</th>\n",
       "      <th>RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2377</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>-0.005967</td>\n",
       "      <td>0.136699</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.493354</td>\n",
       "      <td>-0.007660</td>\n",
       "      <td>-0.585497</td>\n",
       "      <td>-0.001063</td>\n",
       "      <td>-0.351363</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>-0.324675</td>\n",
       "      <td>-0.019275</td>\n",
       "      <td>-0.291751</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5198</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>-0.269520</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313575</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.071338</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>-0.405243</td>\n",
       "      <td>-0.003276</td>\n",
       "      <td>-0.424336</td>\n",
       "      <td>-0.010489</td>\n",
       "      <td>-0.050591</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8017</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>-0.014405</td>\n",
       "      <td>0.192655</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.367499</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>-0.405562</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>-0.315935</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>-0.474957</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>-0.260130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20826</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.430916</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023598</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.079711</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>-0.230167</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>-0.312123</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>-0.226628</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33843</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>-0.006523</td>\n",
       "      <td>-0.060371</td>\n",
       "      <td>-0.007632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337686</td>\n",
       "      <td>-0.007224</td>\n",
       "      <td>-0.161117</td>\n",
       "      <td>-0.001461</td>\n",
       "      <td>-0.095494</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.471895</td>\n",
       "      <td>-0.038752</td>\n",
       "      <td>1.532045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  DATE  STOCK  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY  \\\n",
       "0   2377     1      0        37              12       5            94   \n",
       "1   5198     4      0        37              12       5            94   \n",
       "2   8017     5      0        37              12       5            94   \n",
       "3  20826    11      0        37              12       5            94   \n",
       "4  33843    21      0        37              12       5            94   \n",
       "\n",
       "      RET_1  VOLUME_1     RET_2  ...  VOLUME_16    RET_17  VOLUME_17  \\\n",
       "0 -0.005967  0.136699  0.009031  ...  -0.493354 -0.007660  -0.585497   \n",
       "1  0.001348 -0.269520  0.011100  ...  -0.313575  0.007867   0.071338   \n",
       "2 -0.014405  0.192655  0.003614  ...  -0.367499 -0.005843  -0.405562   \n",
       "3  0.008938  0.430916  0.002662  ...   0.023598  0.011266   0.079711   \n",
       "4 -0.006523 -0.060371 -0.007632  ...  -0.337686 -0.007224  -0.161117   \n",
       "\n",
       "     RET_18  VOLUME_18    RET_19  VOLUME_19    RET_20  VOLUME_20    RET  \n",
       "0 -0.001063  -0.351363  0.005127  -0.324675 -0.019275  -0.291751  False  \n",
       "1  0.007733  -0.405243 -0.003276  -0.424336 -0.010489  -0.050591  False  \n",
       "2  0.002930  -0.315935  0.010462  -0.474957 -0.003541  -0.260130   True  \n",
       "3  0.019038  -0.230167 -0.000287  -0.312123  0.008682  -0.226628   True  \n",
       "4 -0.001461  -0.095494  0.012667   0.471895 -0.038752   1.532045  False  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('x_train.csv', index_col='ID')\n",
    "y_train = pd.read_csv('y_train.csv', index_col='ID')\n",
    "train = pd.concat([x_train, y_train], axis=1)\n",
    "test = pd.read_csv('x_test.csv', index_col='ID')\n",
    "# Ensure proper time ordering within each stock\n",
    "train = train.sort_values(['STOCK', 'DATE']).reset_index()\n",
    "test  = test.sort_values(['STOCK', 'DATE']).reset_index()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with new features\n",
    "From v2, we know:\n",
    "- VOLUME_1 is #1 for both models → Confirms volume is critical\n",
    "- vol_5d is #2 for both → Volatility is key predictor\n",
    "- Rank-based features appear in top 20 for both models\n",
    "Differences between models:\n",
    "- XGBoost loves raw features: VOLUME_1 (340), vol_5d (251)\n",
    "- LightGBM prefers engineered features: RET_1_vs_sector_med (0.0317), RET_1_cs_zscore (0.0302)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying to train...\n",
      "  Creating enhanced rank-based features...\n",
      "  Adding technical indicators...\n",
      "✓ Train shape: (418595, 129)\n",
      "\n",
      "Applying to test...\n",
      "  Creating enhanced rank-based features...\n",
      "  Adding technical indicators...\n",
      "✓ Test shape: (198429, 128)\n"
     ]
    }
   ],
   "source": [
    "def create_enhanced_cross_sectional_features(df):\n",
    "    \"\"\"Combined v2 cross-sectional and lucabri technical features\"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    print(\"  Creating enhanced rank-based features...\")\n",
    "    \n",
    "    if 'DATE' not in df_new.columns:\n",
    "        return df_new\n",
    "    \n",
    "    # 1. PERCENTILE RANKS\n",
    "    for col in [f'RET_{i}' for i in range(1, 21)]:\n",
    "        if col in df_new.columns:\n",
    "            df_new[f'{col}_pctrank'] = df_new.groupby('DATE')[col].rank(pct=True)\n",
    "    \n",
    "    # 2. SECTOR-RELATIVE RANKS\n",
    "    if 'SECTOR' in df_new.columns:\n",
    "        for col in [f'RET_{i}' for i in range(1, 11)]:\n",
    "            if col in df_new.columns:\n",
    "                df_new[f'{col}_sector_pctrank'] = df_new.groupby(['DATE', 'SECTOR'])[col].rank(pct=True)\n",
    "    \n",
    "    # 3. VOLUME RANKS\n",
    "    for col in [f'VOLUME_{i}' for i in range(1, 11) if f'VOLUME_{i}' in df_new.columns]:\n",
    "        df_new[f'{col}_pctrank'] = df_new.groupby('DATE')[col].rank(pct=True)\n",
    "    \n",
    "    # 4. CROSS-SECTIONAL Z-SCORES\n",
    "    for col in [f'RET_{i}' for i in range(1, 11)]:\n",
    "        if col in df_new.columns:\n",
    "            df_new[f'{col}_cs_zscore'] = df_new.groupby('DATE')[col].transform(\n",
    "                lambda x: (x - x.mean()) / (x.std() + 1e-8)\n",
    "            )\n",
    "    \n",
    "    # 5. RELATIVE TO SECTOR MEDIAN\n",
    "    if 'SECTOR' in df_new.columns:\n",
    "        for col in [f'RET_{i}' for i in range(1, 6)]:\n",
    "            if col in df_new.columns:\n",
    "                sector_median = df_new.groupby(['DATE', 'SECTOR'])[col].transform('median')\n",
    "                df_new[f'{col}_vs_sector_med'] = df_new[col] - sector_median\n",
    "    \n",
    "    # 6. COMPOSITE MOMENTUM RANKS\n",
    "    df_new['momentum_1_5'] = df_new[[f'RET_{i}' for i in range(1, 6)]].mean(axis=1)\n",
    "    df_new['momentum_1_5_pctrank'] = df_new.groupby('DATE')['momentum_1_5'].rank(pct=True)\n",
    "    \n",
    "    df_new['momentum_6_20'] = df_new[[f'RET_{i}' for i in range(6, 21)]].mean(axis=1)\n",
    "    df_new['momentum_6_20_pctrank'] = df_new.groupby('DATE')['momentum_6_20'].rank(pct=True)\n",
    "    \n",
    "    # 7. VOLATILITY RANKS\n",
    "    df_new['vol_5d'] = df_new[[f'RET_{i}' for i in range(1, 6)]].std(axis=1)\n",
    "    df_new['vol_5d_pctrank'] = df_new.groupby('DATE')['vol_5d'].rank(pct=True)\n",
    "    \n",
    "    # 8. RETURN-TO-VOLATILITY RATIO\n",
    "    df_new['ret_vol_ratio'] = df_new['momentum_1_5'] / (df_new['vol_5d'] + 1e-8)\n",
    "    df_new['ret_vol_ratio_pctrank'] = df_new.groupby('DATE')['ret_vol_ratio'].rank(pct=True)\n",
    "    \n",
    "    print(\"  Adding technical indicators...\")\n",
    "    \n",
    "    # 9. SECTOR AGGREGATES\n",
    "    if 'SECTOR' in df_new.columns:\n",
    "        for shift in [1, 2, 3, 4]:\n",
    "            feat = f'RET_{shift}'\n",
    "            if feat in df_new.columns:\n",
    "                df_new[f'{feat}_sector_mean'] = df_new.groupby(['SECTOR', 'DATE'])[feat].transform('mean')\n",
    "    \n",
    "    # 10. WEEKLY STATISTICS\n",
    "    for week in range(1, 5):\n",
    "        ret_cols = [f'RET_{(week-1)*5 + d}' for d in range(1, 6) if f'RET_{(week-1)*5 + d}' in df_new.columns]\n",
    "        vol_cols = [f'VOLUME_{(week-1)*5 + d}' for d in range(1, 6) if f'VOLUME_{(week-1)*5 + d}' in df_new.columns]\n",
    "        \n",
    "        if ret_cols:\n",
    "            df_new[f'ret_week{week}_mean'] = df_new[ret_cols].mean(axis=1)\n",
    "            df_new[f'ret_week{week}_std'] = df_new[ret_cols].std(axis=1)\n",
    "        if vol_cols:\n",
    "            df_new[f'vol_week{week}_mean'] = df_new[vol_cols].mean(axis=1)\n",
    "    \n",
    "    # 11. RSI (RELATIVE STRENGTH INDEX)\n",
    "    if 'SECTOR' in df_new.columns:\n",
    "        ret_20 = [f'RET_{i}' for i in range(1, 21) if f'RET_{i}' in df_new.columns]\n",
    "        if ret_20:\n",
    "            gains = df_new.groupby(['SECTOR', 'DATE'])[ret_20].mean().agg(lambda x: x[x>0].mean(), axis=1)\n",
    "            losses = df_new.groupby(['SECTOR', 'DATE'])[ret_20].mean().agg(lambda x: x[x<0].mean(), axis=1).abs()\n",
    "            rs = gains / losses\n",
    "            rsi = 100 - (100 / (1 + rs))\n",
    "            df_new = df_new.join(rsi.to_frame('rsi_sector'), on=['SECTOR', 'DATE'], how='left')\n",
    "    \n",
    "    # 12. ADL (ADVANCE-DECLINE LINE)\n",
    "    if 'SECTOR' in df_new.columns:\n",
    "        ret_5 = [f'RET_{i}' for i in range(1, 6) if f'RET_{i}' in df_new.columns]\n",
    "        if ret_5:\n",
    "            adl = df_new.groupby(['SECTOR', 'DATE'])[ret_5].apply(\n",
    "                lambda x: (x > 0).sum().sum() - (x < 0).sum().sum()\n",
    "            )\n",
    "            df_new = df_new.join(adl.to_frame('adl_sector'), on=['SECTOR', 'DATE'], how='left')\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "\n",
    "# Apply enhanced features\n",
    "print(\"\\nApplying to train...\")\n",
    "train_eng = create_enhanced_cross_sectional_features(train)\n",
    "print(f\"✓ Train shape: {train_eng.shape}\")\n",
    "\n",
    "print(\"\\nApplying to test...\")\n",
    "test_eng = create_enhanced_cross_sectional_features(test)\n",
    "print(f\"✓ Test shape: {test_eng.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model training and feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "categorical_cols = ['DATE', 'STOCK', 'INDUSTRY', 'INDUSTRY_GROUP', 'SECTOR', 'SUB_INDUSTRY']\n",
    "exclude_cols = ['ID', 'RET'] + categorical_cols\n",
    "feature_cols = [col for col in train_eng.columns if col not in exclude_cols]\n",
    "\n",
    "X_train = train_eng[feature_cols].copy()\n",
    "y_train = train_eng['RET'].astype(int)\n",
    "\n",
    "X_train_imp = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_imp = pd.DataFrame(\n",
    "    imputer.transform(test_eng[feature_cols]),\n",
    "    columns=test_eng[feature_cols].columns,\n",
    "    index=test_eng.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline RF...\n",
      "\n",
      "Top 50 features:\n",
      "                  feature  importance\n",
      "106     RET_4_sector_mean    0.067508\n",
      "105     RET_3_sector_mean    0.059645\n",
      "103     RET_1_sector_mean    0.050761\n",
      "119            rsi_sector    0.038356\n",
      "32                 RET_17    0.033857\n",
      "104     RET_2_sector_mean    0.033352\n",
      "120            adl_sector    0.031354\n",
      "99                 vol_5d    0.029306\n",
      "108         ret_week1_std    0.026875\n",
      "80        RET_1_cs_zscore    0.024932\n",
      "1                VOLUME_1    0.022914\n",
      "0                   RET_1    0.021276\n",
      "70       VOLUME_1_pctrank    0.020280\n",
      "100        vol_5d_pctrank    0.020194\n",
      "90    RET_1_vs_sector_med    0.018039\n",
      "116        ret_week4_mean    0.016129\n",
      "40          RET_1_pctrank    0.014922\n",
      "97          momentum_6_20    0.013062\n",
      "111         ret_week2_std    0.011968\n",
      "114         ret_week3_std    0.011215\n",
      "57         RET_18_pctrank    0.011185\n",
      "117         ret_week4_std    0.011098\n",
      "4                   RET_3    0.010809\n",
      "86        RET_7_cs_zscore    0.010806\n",
      "110        ret_week2_mean    0.009973\n",
      "60   RET_1_sector_pctrank    0.009961\n",
      "12                  RET_7    0.009230\n",
      "81        RET_2_cs_zscore    0.009078\n",
      "26                 RET_14    0.008327\n",
      "25              VOLUME_13    0.008225\n",
      "2                   RET_2    0.007820\n",
      "89       RET_10_cs_zscore    0.007505\n",
      "6                   RET_4    0.007424\n",
      "109        vol_week1_mean    0.007368\n",
      "30                 RET_16    0.007231\n",
      "96   momentum_1_5_pctrank    0.007211\n",
      "107        ret_week1_mean    0.007193\n",
      "5                VOLUME_3    0.006893\n",
      "52         RET_13_pctrank    0.006746\n",
      "95           momentum_1_5    0.006554\n",
      "113        ret_week3_mean    0.006508\n",
      "34                 RET_18    0.006305\n",
      "24                 RET_13    0.005851\n",
      "14                  RET_8    0.005795\n",
      "55         RET_16_pctrank    0.005564\n",
      "31              VOLUME_16    0.005561\n",
      "101         ret_vol_ratio    0.005552\n",
      "41          RET_2_pctrank    0.005403\n",
      "38                 RET_20    0.005247\n",
      "46          RET_7_pctrank    0.005193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Baseline RF for feature importance\n",
    "print(\"\\nTraining baseline RF...\")\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    min_samples_split=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_baseline.fit(X_train_imp, y_train)\n",
    "\n",
    "# Feature importance\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X_train_imp.columns,\n",
    "    'importance': rf_baseline.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 50 features:\")\n",
    "print(feat_imp.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reduced from 121 to 50 features\n",
      "\n",
      "1. Training XGBoost...\n",
      "Fold 1: Accuracy=0.5170, AUC=0.5228\n",
      "Fold 2: Accuracy=0.5167, AUC=0.5204\n",
      "Fold 3: Accuracy=0.5163, AUC=0.5208\n",
      "Fold 4: Accuracy=0.5147, AUC=0.5218\n",
      "Fold 5: Accuracy=0.5200, AUC=0.5287\n",
      "\n",
      "2. Training LightGBM...\n",
      "Fold 1: Accuracy=0.5102, AUC=0.5144\n",
      "Fold 2: Accuracy=0.5181, AUC=0.5227\n",
      "Fold 3: Accuracy=0.5183, AUC=0.5247\n",
      "Fold 4: Accuracy=0.5161, AUC=0.5206\n",
      "Fold 5: Accuracy=0.5180, AUC=0.5235\n",
      "\n",
      "3. Training RandomForest...\n",
      "Fold 1: Accuracy=0.5068, AUC=0.5124\n",
      "Fold 2: Accuracy=0.5167, AUC=0.5243\n",
      "Fold 3: Accuracy=0.5165, AUC=0.5241\n",
      "Fold 4: Accuracy=0.5148, AUC=0.5218\n",
      "Fold 5: Accuracy=0.5166, AUC=0.5252\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "XGBoost:\n",
      "  Mean Accuracy:  0.5169 (±0.0017)\n",
      "  Mean AUC:       0.5229 (±0.0030)\n",
      "\n",
      "LightGBM:\n",
      "  Mean Accuracy:  0.5161 (±0.0031)\n",
      "  Mean AUC:       0.5212 (±0.0036)\n",
      "\n",
      "RandomForest:\n",
      "  Mean Accuracy:  0.5143 (±0.0038)\n",
      "  Mean AUC:       0.5216 (±0.0047)\n"
     ]
    }
   ],
   "source": [
    "def train_model_cv(X, y, dates, model_name='xgb', n_folds=5):\n",
    "    gkf = GroupKFold(n_splits=n_folds)\n",
    "    results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups=dates)):\n",
    "        X_train_fold = X.iloc[train_idx]\n",
    "        X_val_fold = X.iloc[val_idx]\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        y_val_fold = y.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        if model_name == 'xgb':\n",
    "            model = xgb.XGBClassifier(\n",
    "                n_estimators=300,\n",
    "                max_depth=5,\n",
    "                learning_rate=0.03,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.6,\n",
    "                reg_alpha=0.8,\n",
    "                reg_lambda=2.5,\n",
    "                random_state=42 + fold,\n",
    "                n_jobs=-1,\n",
    "                use_label_encoder=False\n",
    "            )\n",
    "        elif model_name == 'lgb':\n",
    "            model = lgb.LGBMClassifier(\n",
    "                n_estimators=300,\n",
    "                max_depth=5,\n",
    "                learning_rate=0.02,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.7,\n",
    "                min_child_samples=30,\n",
    "                reg_alpha=1.5,\n",
    "                reg_lambda=3.5,\n",
    "                random_state=42 + fold,\n",
    "                n_jobs=-1,\n",
    "                verbose=-1\n",
    "            )\n",
    "        elif model_name == 'rf':\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=500,\n",
    "                max_depth=6,\n",
    "                min_samples_split=20,\n",
    "                min_samples_leaf=10,\n",
    "                max_features='sqrt',\n",
    "                random_state=42 + fold,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict with standard threshold (0.5)\n",
    "        val_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "        y_pred = (val_proba > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(y_val_fold, y_pred)\n",
    "        auc = roc_auc_score(y_val_fold, val_proba)\n",
    "        \n",
    "        results.append({\n",
    "            'Fold': fold+1,\n",
    "            'Accuracy': acc,\n",
    "            'AUC': auc,\n",
    "            'Model': model,\n",
    "            'Feature_Names': X.columns.tolist()\n",
    "        })\n",
    "        \n",
    "        print(f\"Fold {fold+1}: Accuracy={acc:.4f}, AUC={auc:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "top_features = feat_imp.head(50)['feature'].tolist()\n",
    "X_train_top = X_train_imp[top_features]\n",
    "X_test_top = X_test_imp[top_features]\n",
    "\n",
    "print(f\"\\nReduced from {X_train_imp.shape[1]} to {X_train_top.shape[1]} features\")\n",
    "\n",
    "# Now train with selected features\n",
    "print(\"\\n1. Training XGBoost...\")\n",
    "xgb_results = train_model_cv(X_train_top, y_train, train_eng['DATE'].values, 'xgb')\n",
    "\n",
    "print(\"\\n2. Training LightGBM...\")\n",
    "lgb_results = train_model_cv(X_train_top, y_train, train_eng['DATE'].values, 'lgb')\n",
    "\n",
    "print(\"\\n3. Training RandomForest...\")\n",
    "rf_results = train_model_cv(X_train_top, y_train, train_eng['DATE'].values, 'rf')\n",
    "# ============================================================================\n",
    "# MODEL COMPARISON SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name, results in [('XGBoost', xgb_results), ('LightGBM', lgb_results), ('RandomForest', rf_results)]:\n",
    "    acc_mean = np.mean([r['Accuracy'] for r in results])\n",
    "    acc_std = np.std([r['Accuracy'] for r in results])\n",
    "    auc_mean = np.mean([r['AUC'] for r in results])\n",
    "    auc_std = np.std([r['AUC'] for r in results])\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Mean Accuracy:  {acc_mean:.4f} (±{acc_std:.4f})\")\n",
    "    print(f\"  Mean AUC:       {auc_mean:.4f} (±{auc_std:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
